# Intro.

Publish-subcribe model.

## Messages
message is an array of bytes.
message's may have a key associated with them. Also a byte array
Bpoth have not particular format or meanin gto kafka.
Keys are used when writing to specific **partitions** in a controlled way. usually using the hash of the key % no of partitions.

messages are written in batches.
all messages in a batch are of the same **topic** and partition.

## Schemas
Schemas define the format of the messags.
They are stored in a repository, accessible to subscribers and publishers so that they can be updated in a coordinated way.

## Topics
Topics are broken down into separate partitions.
Messages are written to the end of a partition, similar to a commit log.
The ordering of messages is only maintained within a single partition but not within the topic itself.
Different partitions can be hosted on different servers, allowing a single topic to be scaled horizontally.
Partitions may be replicated on different servers to allow redundancy and fallbacks in case a server goes down.

## Producers/Consumers
These are Kafka clients.
Producers add messages to a Kafka topic, while consumers read the messages from them.

There are two API's:
- Kafka connect API for producers
- Kafka streams for for producers.

When producers add messages to specific topic, the messages are usually added to partitions evenly (using the modulo of the key). But it is sometimes desirable to have them target a specific paritition. This can be achieved by choosing a specific key, or by creating a custom partitioner that may follow other rules.

Consumers track which messages they have ready by an "offset" integer value. This is generated by Kafka and assocaited with each message, and unique to each partition. So they value doesn't necessarily increase incrementally.
The offet for a consumer is usually stored and managed by Kafka, so if the consumer goes down then once it is back up it will now which message it should carry on from.

Consumers also work as part of a "consumer group". This may consist of one or more consumers.
There may be multiple consumer groups for a given topic.
Each partition within a topic will have a single consumer from any given group. But a single consumer may read from multiple partitions.
If one consumer goes down then the other consumers can be re-assigned so that they are also reading from its partitions.

## Brokers and Clusters.
Each Kafka server is referred to as a "Broker".
All brokers will be part of a "cluster" and one such broker is elected automatically as the "controller".
Should any one the brokers go offline the controller is responsible for reassigning brokers to partitions.
Each broker can handle many partitions (thousands).
As mentioned, partitions may be replicated to other brokers.
In this case, one of the brokers is considered the "leader" of that partition, while the others, that hold the replications, are called "followers".

Stored messages are not kept for ever and will eventually be purged.
This can be configured to occur either by a configured expirey time, or by monitoring the disk space used.